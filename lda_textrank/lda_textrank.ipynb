{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sunild/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/sunild/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import networkx as nx\n",
    "from rouge import Rouge\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words('english'))\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import nltk.data\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "import string\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "rouge_=Rouge()\n",
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FIXED VARIABLES DECLARED\n",
    "\"\"\"\n",
    "EMBEDDING_SIZE=100 # OPTIONS: 50,100,200,300\n",
    "SENT_SUMMARY_COUNT=5\n",
    "SENT_SUMMARY_THERSHOLD=0.35\n",
    "HI_DATA_PATH='../data/hi-data/test.csv' # BOTH ARTICLES AND SUMMARIES\n",
    "EN_DATA_PATH_SRC='../data/preprocessed_truncated/test.txt.src.tokenized.fixed.cleaned.final.truncated.txt' # ONLY ARTICLES\n",
    "EN_DATA_PATH_TGT='../data/preprocessed_truncated/test.txt.tgt.tokenized.fixed.cleaned.final.truncated.txt' # ONLY SUMMARIES\n",
    "HI_EMBEDDINGS_PATH='../data/glove/hi/hi-d100-glove.txt'\n",
    "EN_EMBEDDINGS_PATH='../data/glove/en/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 400000 words loaded from glove model, each of size 100.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "HELPER FUNCTIONS FOR MAIN SUMMARY GENERATION FUNC\n",
    "\"\"\"\n",
    "def cosine_similarity(a,b):\n",
    "    return np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "\n",
    "def load_glove_model(file_path):\n",
    "    \"\"\"\n",
    "    function to load glove embeddings from txt file into a dict\n",
    "    \"\"\"\n",
    "    glove_model = {}\n",
    "    with open(file_path,'r',encoding=\"utf-8\",errors='ignore') as f:\n",
    "        try:\n",
    "            for i,line in enumerate(f):\n",
    "                # if i%10000==0:\n",
    "                #     print(i)\n",
    "                split_line = line.split()\n",
    "                word = split_line[0]\n",
    "                embedding = np.array(split_line[-EMBEDDING_SIZE:], dtype=np.float64)\n",
    "                glove_model[word] = embedding\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(line,i)\n",
    "    print(f\"total {len(glove_model)} words loaded from glove model, each of size {EMBEDDING_SIZE}.\")\n",
    "    return glove_model\n",
    "\n",
    "# load glove embeddings for both hindi and english\n",
    "glove_embeddings=load_glove_model(file_path=EN_EMBEDDINGS_PATH)\n",
    "# hi_glove_embeddings=load_glove_model(file_path=HI_EMBEDDINGS_PATH)\n",
    "# save all glove embeddings in a single dict\n",
    "# this takes care of both languages that are present in hindi texts; although it makes overall process a bit slow\n",
    "# glove_embeddings.update(hi_glove_embeddings)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: DeprecationWarning: invalid escape sequence \\,\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=[\"gop eyes gains as voters in 11 states pick governors enlarge this image toggle caption jim cole/ap jim cole/ap voters in 11 states will pick their governors tonight , and republicans appear on track to increase their numbers by at least one , with the potential to extend their hold to more than two-thirds of the nation ' s top state offices . eight of the gubernatorial seats up for grabs are now held by democrats ; three are in republican hands . republicans currently hold 29 governorships , democrats have 20 , and rhode island ' s gov . lincoln chafee is an independent . polls and race analysts suggest that only three of tonight ' s contests are considered competitive , all in states where incumbent democratic governors aren ' t running again : montana , new hampshire and washington . while those state races remain too close to call , republicans are expected to wrest the north carolina governorship from democratic control , and to easily win gop-held seats in utah , north dakota and indiana . democrats are likely to hold on to their seats in west virginia and missouri , and are expected to notch safe wins in races for seats they hold in vermont and delaware . holding sway on health care while the occupant of the governor ' s office is historically far less important than the party that controls the state legislature , top state officials in coming years are expected to story_separator_special_tag gop eyes gains as voters in 11 states pick governors jim cole / ap i jim cole / ap voters in 11 states will pick their governors tonight , and republicans appear on track to increase their numbers by at least one , and with the potential to extend their hold to more than two-thirds of the nation ' s top state offices . eight of the gubernatorial seats up for grabs today are now held by democrats ; three are in republican hands . republicans currently hold 29 governorships , democrats have 20 ; and rhode island ' s gov . lincoln chafee is an independent . polls and race analysts suggest that only three of tonight ' s contests are considered competitive , all in states where incumbent democratic governors aren ' t running again : montana , new hampshire and washington . while those state races remain too close to call , republicans are expected to wrest the north carolina governorship from democratic control , and to easily win gop-held seats in utah , north dakota and indiana . democrats are likely hold on to their seats in west virginia and missouri ; and expected to notch safe wins in races for seats they hold in vermont and delaware . holding sway on health care while the occupant of the governor ' s office is historically far less important than the party that controls the state legislature , top state officials in coming years are expected to\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_vect(probe_text):\n",
    "    \"\"\"\n",
    "    func to return sent vectors\n",
    "    \"\"\"\n",
    "\n",
    "    break_sentences=tokenizer.tokenize(probe_text)\n",
    "    clean_sentences=[]\n",
    "    for item in break_sentences:\n",
    "      item=item.translate(str.maketrans('', '', string.punctuation))\n",
    "      item=' '.join( [w for w in item.split() if len(w)>1] )\n",
    "      words = word_tokenize(item)\n",
    "      words = [word for word in words if len(words)>1]\n",
    "      words = [word.lower() for word in words]\n",
    "      words = [word for word in words if word not in stop_words]\n",
    "      item=' '.join(words)    \n",
    "      clean_sentences.append(item)\n",
    "    cln_summ=''\n",
    "    cln_summ = '.'.join(clean_sentences)\n",
    "    # print(cln_summ)\n",
    "    #print(cln_summ)\n",
    "    tfidf = CountVectorizer()\n",
    "    response = tfidf.fit_transform([cln_summ])\n",
    "    #print(response)\n",
    "    unique_word_list = tfidf.get_feature_names_out()\n",
    "    tf_idf={}\n",
    "    for col in response.nonzero()[1]:\n",
    "      tf_idf[unique_word_list[col]]= response[0, col]\n",
    "    svd_matrix=np.zeros([len(unique_word_list),len(clean_sentences)])\n",
    "    for i in range(0,len(clean_sentences)):\n",
    "      sen=clean_sentences[i].split()\n",
    "      for val in sen:\n",
    "        #print(val)\n",
    "        index=np.where(unique_word_list == val)\n",
    "        index_length=len(index[0])\n",
    "        if(index_length == 1):\n",
    "          svd_matrix[index,i]=tf_idf[val]\n",
    "    #print(svd_matrix)\n",
    "    u,sigma,v_trans=np.linalg.svd(svd_matrix,full_matrices=False,compute_uv=True)\n",
    "    sum_sigma=np.sum(sigma)\n",
    "    iter_sum=0\n",
    "    check_coverage=0\n",
    "    for i in range(0,len(sigma)):\n",
    "      iter_sum=iter_sum+sigma[i]\n",
    "      percent_contribution=iter_sum/sum_sigma\n",
    "      #print(\"the percent contributuin is \",percent_contribution)\n",
    "      if(percent_contribution<0.70):\n",
    "        check_coverage=i+1\n",
    "    u_trimmed=u[:,:check_coverage]\n",
    "    v_trimmed=v_trans[:check_coverage,:]\n",
    "\n",
    "    sent_vects=[]\n",
    "    for i,sent in enumerate(clean_sentences):\n",
    "        # sent_words=sent.split(' ')\n",
    "        tmp_=0\n",
    "        for k,concept_weight in enumerate(v_trimmed[:,i]):\n",
    "            foo_=0\n",
    "            for j,word in enumerate(unique_word_list):\n",
    "                if word in glove_embeddings:\n",
    "                    # print('it is')\n",
    "                    foo_+=u_trimmed[j,k]*glove_embeddings[word]\n",
    "            tmp_+=concept_weight*foo_\n",
    "        \n",
    "        sent_vects.append(tmp_)\n",
    "      \n",
    "    return sent_vects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(article_text):\n",
    "    \"\"\"\n",
    "    function to get summary of article text\n",
    "    \"\"\"\n",
    "    sent_tokens=sent_tokenize(article_text)\n",
    "    sent_vects=get_sent_vect(article_text)\n",
    "    \n",
    "    total_sents=len(sent_vects)\n",
    "    similarity_mat=np.zeros((total_sents,total_sents))\n",
    "    \n",
    "    for i in range(total_sents):\n",
    "        for j in range(total_sents):\n",
    "            # this way diag entries will be zeros\n",
    "            if i!=j:\n",
    "                similarity_mat[i][j]=cosine_similarity(sent_vects[i],sent_vects[j])\n",
    "\n",
    "    # create graph from similarity matrix\n",
    "    network_graph=nx.from_numpy_array(similarity_mat)\n",
    "    \"\"\"\n",
    "    apply pagerank algo to get scores\n",
    "    \"\"\"\n",
    "    scores=nx.pagerank(network_graph, alpha=0.85, max_iter=1000)\n",
    "    sorted_scores = sorted(((scores[i],sent_token) for i,sent_token in enumerate(sent_tokens)), reverse=True)\n",
    "\n",
    "    # TODO: implement thershold version\n",
    "    # in case some article does not have enough sentences\n",
    "    if total_sents > SENT_SUMMARY_COUNT:\n",
    "        summary_text=' '.join([sorted_scores[i][1] for i in range(SENT_SUMMARY_COUNT)])\n",
    "    else:\n",
    "        summary_text=' '.join([sorted_scores[i][1] for i in range(total_sents)])\n",
    "\n",
    "    return summary_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"while those state races remain too close to call , republicans are expected to wrest the north carolina governorship from democratic control , and to easily win gop-held seats in utah , north dakota and indiana . while those state races remain too close to call , republicans are expected to wrest the north carolina governorship from democratic control , and to easily win gop-held seats in utah , north dakota and indiana . democrats are likely to hold on to their seats in west virginia and missouri , and are expected to notch safe wins in races for seats they hold in vermont and delaware . democrats are likely hold on to their seats in west virginia and missouri ; and expected to notch safe wins in races for seats they hold in vermont and delaware . polls and race analysts suggest that only three of tonight ' s contests are considered competitive , all in states where incumbent democratic governors aren ' t running again : montana , new hampshire and washington .\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_summary(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gop eyes gains voters 11 states pick governors enlarge image toggle caption jim coleap jim coleap voters 11 states pick governors tonight republicans appear track increase numbers least one potential extend hold twothirds nation top state offices.eight gubernatorial seats grabs held democrats three republican hands.republicans currently hold 29 governorships democrats 20 rhode island gov.lincoln chafee independent.polls race analysts suggest three tonight contests considered competitive states incumbent democratic governors running montana new hampshire washington.state races remain close call republicans expected wrest north carolina governorship democratic control easily win gopheld seats utah north dakota indiana.democrats likely hold seats west virginia missouri expected notch safe wins races seats hold vermont delaware.holding sway health care occupant governor office historically far less important party controls state legislature top state officials coming years expected storyseparatorspecialtag gop eyes gains voters 11 states pick governors jim cole ap jim cole ap voters 11 states pick governors tonight republicans appear track increase numbers least one potential extend hold twothirds nation top state offices.eight gubernatorial seats grabs today held democrats three republican hands.republicans currently hold 29 governorships democrats 20 rhode island gov.lincoln chafee independent.polls race analysts suggest three tonight contests considered competitive states incumbent democratic governors running montana new hampshire washington.state races remain close call republicans expected wrest north carolina governorship democratic control easily win gopheld seats utah north dakota indiana.democrats likely hold seats west virginia missouri expected notch safe wins races seats hold vermont delaware.holding sway health care occupant governor office historically far less important party controls state legislature top state officials coming years expected\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(0,1):\n",
    "  #print(i)\n",
    "    probe_text=documents[i]\n",
    "    ground_truth=clean_summ[i]\n",
    "    break_sentences=tokenizer.tokenize(probe_text)\n",
    "    clean_sentences=[]\n",
    "    for item in break_sentences:\n",
    "      item=item.translate(str.maketrans('', '', string.punctuation))\n",
    "      item=' '.join( [w for w in item.split() if len(w)>1] )\n",
    "      words = word_tokenize(item)\n",
    "      words = [word for word in words if len(words)>1]\n",
    "      words = [word.lower() for word in words]\n",
    "      words = [word for word in words if word not in stop_words]\n",
    "      item=' '.join(words)    \n",
    "      clean_sentences.append(item)\n",
    "    cln_summ=''\n",
    "    cln_summ = '.'.join(clean_sentences)\n",
    "    print(cln_summ)\n",
    "    #print(cln_summ)\n",
    "    tfidf = CountVectorizer()\n",
    "    response = tfidf.fit_transform([cln_summ])\n",
    "    #print(response)\n",
    "    unique_word_list = tfidf.get_feature_names_out()\n",
    "    tf_idf={}\n",
    "    for col in response.nonzero()[1]:\n",
    "      tf_idf[unique_word_list[col]]= response[0, col]\n",
    "    svd_matrix=np.zeros([len(unique_word_list),len(clean_sentences)])\n",
    "    for i in range(0,len(clean_sentences)):\n",
    "      sen=clean_sentences[i].split()\n",
    "      for val in sen:\n",
    "        #print(val)\n",
    "        index=np.where(unique_word_list == val)\n",
    "        index_length=len(index[0])\n",
    "        if(index_length == 1):\n",
    "          svd_matrix[index,i]=tf_idf[val]\n",
    "    #print(svd_matrix)\n",
    "    u,sigma,v_trans=np.linalg.svd(svd_matrix,full_matrices=False,compute_uv=True)\n",
    "    sum_sigma=np.sum(sigma)\n",
    "    iter_sum=0\n",
    "    check_coverage=0\n",
    "    for i in range(0,len(sigma)):\n",
    "      iter_sum=iter_sum+sigma[i]\n",
    "      percent_contribution=iter_sum/sum_sigma\n",
    "      #print(\"the percent contributuin is \",percent_contribution)\n",
    "      if(percent_contribution<0.70):\n",
    "        check_coverage=i+1\n",
    "    u_trimmed=u[:,:check_coverage]\n",
    "    v_trimmed=v_trans[:check_coverage,:]\n",
    "    # print(\"the shape of u_trimed is\",u_trimmed.shape)\n",
    "    # print(\"the shape of v trimmed is \",v_trimmed.shape)\n",
    "    # print((unique_word_list))\n",
    "    # chosen_sen_index=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vects=[]\n",
    "for i,sent in enumerate(clean_sentences):\n",
    "    # sent_words=sent.split(' ')\n",
    "    tmp_=0\n",
    "    for k,concept_weight in enumerate(v_trimmed[:,i]):\n",
    "        foo_=0\n",
    "        for j,word in enumerate(unique_word_list):\n",
    "            if word in glove_embeddings:\n",
    "                # print('it is')\n",
    "                foo_+=u_trimmed[j,k]*glove_embeddings[word]\n",
    "        tmp_+=concept_weight*foo_\n",
    "    \n",
    "    sent_vects.append(tmp_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7251169916658042"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(sent_vects[0],sent_vects[1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d66a3fad9284895a61a090a035e4fcbf146100e906c5a916a78dc9cbee9e65c6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ir')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
